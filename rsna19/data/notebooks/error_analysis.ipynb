{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_OUT_DIR = '/kolos/m2/ct/data/rsna/error_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_paths = [\n",
    "    '/kolos/m2/ct/models/classification/rsna/0_1_2_3/version_0/val_results.csv',\n",
    "    '/kolos/m2/ct/models/classification/rsna/0_1_2_4/version_0/val_results.csv',\n",
    "    '/kolos/m2/ct/models/classification/rsna/0_1_3_4/version_0/val_results.csv',\n",
    "    '/kolos/m2/ct/models/classification/rsna/0_2_3_4/version_0/val_results.csv',\n",
    "    '/kolos/m2/ct/models/classification/rsna/1_2_3_4/version_0/val_results.csv'\n",
    "]\n",
    "\n",
    "df = pd.concat([pd.read_csv(path) for path in csv_paths])\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auxiliary columns\n",
    "\n",
    "class_weights = [1, 1, 1, 1, 1, 2]\n",
    "classes = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']\n",
    "gt_columns = ['gt_' + c for c in classes]\n",
    "pred_columns = ['pred_' + c for c in classes]\n",
    "gt = df[gt_columns]\n",
    "pred = df[pred_columns]\n",
    "\n",
    "losses = F.binary_cross_entropy(torch.tensor(pred.to_numpy()), torch.tensor(gt.to_numpy()), weight=torch.tensor(class_weights, dtype=torch.float64), reduction='none')\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    df['loss_' + c] = pd.Series(losses[:, i].numpy())\n",
    "    \n",
    "losses = losses.mean(dim=1).numpy()\n",
    "df['loss'] = pd.Series(losses)\n",
    "df['study_path'] = df.path.apply(lambda path: '/'.join(path.split('/')[:-2]))\n",
    "\n",
    "df['any_error'] = (df.gt_any - df.pred_any).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save top_n slices with highest overall loss\n",
    "\n",
    "out_dir = ROOT_OUT_DIR + 'highest_loss/'\n",
    "top_n = 1000\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for row in df.sort_values(by='loss', ascending=False)[:top_n + 1].itertuples():\n",
    "    path = row.path\n",
    "    loss = row.loss\n",
    "    pred = [getattr(row, p) for p in pred_columns]\n",
    "    \n",
    "    target_path = os.path.join(os.path.dirname(path), '../vis')\n",
    "    \n",
    "    slice_num = os.path.basename(path).split('.')[0]\n",
    "    pred_str = '{:.02f},{:.02f},{:.02f},{:.02f},{:.02f},{:.02f}'.format(*pred)\n",
    "    link_name = f'loss={loss:.04f},slice={slice_num},pred={pred_str}'\n",
    "    link_name = os.path.join(out_dir, link_name)\n",
    "    try:\n",
    "        os.symlink(target_path, link_name)\n",
    "    except FileExistsError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save positive and negative scans with any_error in specified ranges\n",
    "\n",
    "error_ranges = [(0.05, 0.2), (0.2, 0.5), (0.5, 0.9), (0.9, 1.0)]\n",
    "\n",
    "for min_error, max_error in error_ranges:\n",
    "    error_range_dir = f'error={min_error:.02f}-{max_error:0.2f}'\n",
    "    neg_dir = os.path.join(ROOT_OUT_DIR, 'negatives', error_range_dir)\n",
    "    pos_dir = os.path.join(ROOT_OUT_DIR, 'positives', error_range_dir)\n",
    "    os.makedirs(neg_dir, exist_ok=True)\n",
    "    os.makedirs(pos_dir, exist_ok=True)\n",
    "\n",
    "    for row in df[(df.any_error > min_error) & (df.any_error < max_error)].itertuples():\n",
    "        path = row.path\n",
    "        error = row.any_error\n",
    "        gt_any = row.gt_any\n",
    "        pred = [getattr(row, p) for p in pred_columns]\n",
    "\n",
    "        target_path = os.path.join(os.path.dirname(path), '../vis')\n",
    "\n",
    "        slice_num = os.path.basename(path).split('.')[0]\n",
    "        pred_str = '{:.02f},{:.02f},{:.02f},{:.02f},{:.02f},{:.02f}'.format(*pred)\n",
    "        link_name = f'error={error:.04f},slice={slice_num},pred={pred_str}'\n",
    "        link_name = os.path.join(pos_dir if gt_any else neg_dir, link_name)\n",
    "        try:\n",
    "            os.symlink(target_path, link_name)\n",
    "        except FileExistsError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save top_n scans with highest loss averaged per scan\n",
    "\n",
    "top_n = 1000\n",
    "highest_loss_exams = df.groupby('study_path', as_index=False).mean().sort_values(by='loss', ascending=False)[:top_n][['study_path', 'loss']]\n",
    "\n",
    "for exam in tqdm(highest_loss_exams.itertuples(), total=top_n):\n",
    "    study_path = exam.study_path\n",
    "    loss = exam.loss\n",
    "    \n",
    "    study_id = os.path.basename(study_path)\n",
    "    out_dir = os.path.join(ROOT_OUT_DIR, 'highest_loss_per_scan', f'loss={loss:.04f},{study_id}')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    for row in df[df.study_path == study_path].itertuples():\n",
    "        path = row.path\n",
    "        slice_loss = row.loss\n",
    "        pred = [getattr(row, p) for p in pred_columns]\n",
    "\n",
    "        target_path = path.replace('npy256', 'vis').replace('.npy', '.png')\n",
    "        target_path = os.path.realpath(target_path)\n",
    "\n",
    "        slice_num = os.path.basename(path).split('.')[0]\n",
    "        pred_str = '{:.02f},{:.02f},{:.02f},{:.02f},{:.02f},{:.02f}'.format(*pred)\n",
    "        link_name = f'slice={slice_num},loss={slice_loss:.04f},pred={pred_str}.png'\n",
    "        link_name = os.path.join(out_dir, link_name)\n",
    "        try:\n",
    "            os.symlink(target_path, link_name)\n",
    "        except FileExistsError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scans with per-class loss averaged over scan (only scans containing specific class)\n",
    "\n",
    "for class_ in classes:\n",
    "    if class_ == 'any':\n",
    "        continue\n",
    "    for variant in ['highest', 'lowest', 'all']:\n",
    "        print(class_, variant)\n",
    "        top_n = 100\n",
    "        root_out_dir = f'{ROOT_OUT_DIR}{class_}_{variant}_loss_per_scan/'\n",
    "        \n",
    "        selected_exams = df.groupby('study_path', as_index=False).mean().sort_values(\n",
    "            by=f'loss_{class_}', ascending=(variant == 'lowest'))\n",
    "        selected_exams = selected_exams[selected_exams[f'gt_{class_}'] > 0][['study_path', f'loss_{class_}']]\n",
    "        if variant != 'all':\n",
    "            selected_exams = selected_exams[:top_n]\n",
    "\n",
    "        for exam in tqdm(selected_exams.itertuples(), total=top_n):\n",
    "            study_path = exam.study_path\n",
    "            loss = getattr(exam, f'loss_{class_}')\n",
    "\n",
    "            study_id = os.path.basename(study_path)\n",
    "            out_dir = f'{ROOT_OUT_DIR}{class_}_{variant}_loss_per_scan/loss={loss:.04f},{study_id}'\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "            for row in df[df.study_path == study_path].itertuples():\n",
    "                path = row.path\n",
    "                slice_loss = row.loss\n",
    "                pred = [getattr(row, p) for p in pred_columns]\n",
    "\n",
    "                target_path = path.replace('npy256', 'vis').replace('.npy', '.png')\n",
    "                target_path = os.path.realpath(target_path)\n",
    "\n",
    "                slice_num = os.path.basename(path).split('.')[0]\n",
    "                pred_str = '{:.02f},{:.02f},{:.02f},{:.02f},{:.02f},{:.02f}'.format(*pred)\n",
    "                link_name = f'slice={slice_num},loss={slice_loss:.04f},pred={pred_str}.png'\n",
    "                link_name = os.path.join(out_dir, link_name)\n",
    "                try:\n",
    "                    os.symlink(target_path, link_name)\n",
    "                except FileExistsError:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
